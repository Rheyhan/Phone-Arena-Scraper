{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6d6a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refubrished code 2025\n",
    "\n",
    "# libraries\n",
    "import cloudscraper # TBH, should have just used selenium if ik it would be this much of a pain.\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import random as rd\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import *\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f520e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_filters = {\n",
    "    \"manufacturers\": ['Apple', 'Samsung', 'Google', 'OnePlus', 'Motorola', 'Sony', 'Xiaomi', 'Nokia', 'Honor', 'DOOGEE', 'Blackview', 'OSCAL', 'Nothing',\n",
    "                       'Asus', 'HTC', 'Huawei', 'HMD', 'BlackBerry', 'ZTE', 'RedMagic', 'LG', 'Kyocera', 'Fairphone', 'Alcatel', 'BLU', 'Razer', 'realme', 'Essential',\n",
    "                        'TCL', 'Orbic', 'CAT', 'RED', 'BOOX', 'Lenovo', 'OPPO', 'Microsoft', 'Acer', 'Garmin', 'Amazon', 'NOA', 'Meizu', 'nubia', 'GIGABYTE', 'Gionee', 'vivo', 'Panasonic',\n",
    "                        'HP', 'Sony Ericsson', 'Maxwest', 'Verizon', 'Yota', 'Doro', 'T-Mobile', 'Sprint', 'Palm', 'Sanyo', 'Casio', 'VERZO', 'TAG Heuer', 'Xolo', 'VIZIO', 'Fujitsu', 'UMX',\n",
    "                        'Garmin-Asus', 'Airo Wireless', 'TerreStar', 'Lumigon', 'FiGO', 'NIU', 'altek', 'Micromax', 'ARCHOS', 'Best Buy', 'Verykool', 'Notion Inc', 'Vertu', 'Sonim', 'Karbonn',\n",
    "                        'ICEMOBILE', 'Emporia', 'Philips', 'Dell', 'ViewSonic', 'Toshiba', 'Barnes & Noble', 'Nvidia', 'PCD', 'Jolla', 'Eten', 'mobiado', 'i-mate', 'General Mobile', \n",
    "                        'Fusion Garage', 'INQ', 'Videocon', 'Coolpad', 'LAVA', 'Saygus', 'Yezz', 'Plum', 'Celkon', 'i-mobile', 'Spice Mobile', 'Zen Mobile', 'Velocity', 'COWON', 'Kogan',\n",
    "                        'AT&T', 'VKMobile', 'Benq-Siemens', 'Helio', 'Haier', 'Lemon Mobiles', 'Handspring', 'Bird', 'Danger', 'WND', 'O2', 'Latte', 'Siemens', 'Pantech', 'Firefly Mobile',\n",
    "                        'Cricket', 'Orange', 'Fly', 'Mitsubishi', 'MiTAC', 'Amoi', 'Sierra Wireless', 'Neonode', 'Sendo', 'Maxon', 'Hitachi', 'Sharp', 'NEC', 'Sagem', 'BenQ', 'Ericsson'],\n",
    "                        \n",
    "    \"deviceType\": { \"Basic phone\"    : \"f[53][bp]=1221\",\n",
    "                    \"Feature phone\"  : \"f[53][fp]=1222\",\n",
    "                    \"Smartphone\"     : \"f[53][sp]=1223\",\n",
    "                    \"Tablet\"         : \"f[53][t]=1612\",\n",
    "                    \"Smartwatch\"     : \"f[53][sw]=2580\"}\n",
    "                    }\n",
    "\n",
    "class scraper():\n",
    "    '''\n",
    "    Tbh idk why i made this overcomplicated if in the end i would just get all the data from phonearena, but yeah. It is what it is.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - manufacturers : Optional[List[str]]\n",
    "        List of manufacturers to filter by. Default is None.\n",
    "    - releaseYear : Optional[List[int]]\n",
    "        List of release years to filter by. Default is None.\n",
    "    - deviceType : Optional[List[str]]\n",
    "        List of device types to filter by. Default is None.\n",
    "    - max_timer : int\n",
    "        Maximum time to wait between requests. Default is 4 seconds.\n",
    "    '''\n",
    "    def __init__(self, manufacturers: Optional[List[str]] = None, releaseYear: Optional[List[int]] = None, \n",
    "                 deviceType: Optional[List[str]] = None, max_timer: int = 4):\n",
    "        '''\n",
    "        NOTE: Only 20 filters can be applied at once on PhoneArena.\n",
    "        '''\n",
    "        self.URL = \"https://www.phonearena.com/phones\"\n",
    "        self.max_timer = max_timer\n",
    "\n",
    "        # Set filters of search\n",
    "        if manufacturers:\n",
    "            self.URL = self.URL + \"/manufacturers/\"\n",
    "            manufacturers = \",\".join([i.lower() for i in manufacturers])\n",
    "            self.URL = self.URL + manufacturers\n",
    "            self.usemanufacturers = True\n",
    "            \n",
    "        use_releaseYear = False\n",
    "        if releaseYear:\n",
    "            self.URL = self.URL + \"?f[y]=\"\n",
    "            if len(releaseYear) > 1:\n",
    "                releaseYear = ','.join([str(i) for i in range(releaseYear[0], releaseYear[-1]+1)])\n",
    "            else:\n",
    "                releaseYear = str(releaseYear[0])\n",
    "            self.URL = self.URL + releaseYear\n",
    "            use_releaseYear = True\n",
    "\n",
    "        if deviceType:\n",
    "            if use_releaseYear:\n",
    "                self.URL = self.URL + \"&\"\n",
    "            else:\n",
    "                self.URL = self.URL + \"?\"\n",
    "            deviceType = \"&\".join([available_filters[\"deviceType\"][i] for i in deviceType])\n",
    "            self.URL = self.URL + deviceType\n",
    "\n",
    "        # Where to store data for each phone\n",
    "        self.gathered_data = {}\n",
    "        self.driver = cloudscraper.create_scraper() # Initialize!\n",
    "\n",
    "    def scape_phone_data(self):\n",
    "        '''\n",
    "        Scrapes data from a single phone page\n",
    "        '''\n",
    "        # Get release date\n",
    "        widget_spec = self.phonespectable.find(\"div\", attrs={\"class\" : \"widgetQuickSpecs\"})\n",
    "        try:\n",
    "            release_date = widget_spec.find(\"div\", attrs={\"class\":\"released specs-element\"}).find(\"span\", attrs={\"class\":\"specs-element-desc\"}).text.strip()\n",
    "        except:\n",
    "            release_date = \"No information\"\n",
    "\n",
    "        self.temp[\"Release date\"] = release_date\n",
    "\n",
    "        # specifications data\n",
    "        full_spec = self.phonespectable.find(\"section\", attrs={\"class\" : \"page__section page__section_specs\"})\n",
    "        spec_tables = full_spec.find_all(\"div\", attrs={\"class\" : \"widgetSpecs\"})\n",
    "\n",
    "        for tabel in spec_tables:\n",
    "            # gets the category of the table\n",
    "            category = tabel.find(\"th\").text.strip()\n",
    "            category_data = {}\n",
    "            for item in tabel.find_all(\"tr\", attrs={\"class\":\"specs-table-title\"}):\n",
    "                attr = item.find(\"th\").text.strip()\n",
    "                val = item.find(\"td\").text.strip()    \n",
    "                category_data[attr] = val\n",
    "            self.temp[category] = category_data\n",
    "\n",
    "    def scrape_result_page(self):\n",
    "        '''\n",
    "        Scrapes a single result page for phone links and gathers data for each phone.\n",
    "        '''\n",
    "        \n",
    "        result = self.soup_result_page.find(\"div\", attrs={\"class\": \"results\"})\n",
    "\n",
    "        phone_result = result.find_all(\"div\", attrs = {\"class\" : \"tile-phone\"})\n",
    "\n",
    "        # Iterate through each phone on the page\n",
    "        for phone in tqdm(phone_result, desc=\"Scraping phones\"):\n",
    "            self.temp = {}  # Temporary storage each phones data\n",
    "            phoneName = phone.find(\"a\", attrs = {\"class\" : \"tile-title\"}).text\n",
    "            phoneHREF = phone.find(\"a\", attrs = {\"class\" : \"tile-title\"}).get(\"href\")\n",
    "            r = self.driver.get(phoneHREF)  # Get phone page\n",
    "            time.sleep(rd.uniform(1,self.max_timer))\n",
    "            self.phonespectable = BeautifulSoup(r.content, \"html5lib\")  # Get soup of the phone page\n",
    "            self.scape_phone_data()\n",
    "\n",
    "            # Store temp to main data dictionary\n",
    "            self.gathered_data[phoneName] = self.temp\n",
    "\n",
    "\n",
    "    def start(self, save_path: str = \"temp.py\", saveas_csv: bool = False):\n",
    "        '''\n",
    "        Starts the scraping process.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        - save_path : str\n",
    "            Path to save the scraped data. Default is \"temp.py\".\n",
    "        - saveas_csv : bool\n",
    "            Whether to save the data as a CSV file. Default is False.\n",
    "        '''\n",
    "\n",
    "        # Get first page\n",
    "        r = self.driver.get(self.URL)\n",
    "        time.sleep(rd.uniform(1,self.max_timer))\n",
    "        self.soup_result_page = BeautifulSoup(r.content, \"html5lib\")\n",
    "\n",
    "        # will get any existing max page number, if none, will just scrape the one page\n",
    "        try:\n",
    "            max_page = int(self.soup_result_page.find(\"nav\", attrs = {\"data-target\":\"finder-content\"}).find_all(\"li\", attrs = {\"class\": \"item\"})[-2].text)\n",
    "            \n",
    "        except:\n",
    "            max_page = 1\n",
    "\n",
    "        pbar = tqdm(total=max_page, desc=\"Scraping pages\")\n",
    "\n",
    "        # Scrape first page\n",
    "        self.scrape_result_page()\n",
    "        pbar.update(1)\n",
    "\n",
    "        # if multiple pages, scrape the rest\n",
    "        if max_page>1:\n",
    "            # Adjust reference URL\n",
    "            if self.usemanufacturers:\n",
    "                # Ts if manufacturers were used as filter\n",
    "                temp = re.search(r'manufacturers/[a-zA-Z,]+', self.URL, re.IGNORECASE)[0]\n",
    "            else:\n",
    "                temp = re.search(r'/phones', self.URL, re.IGNORECASE)[0]\n",
    "\n",
    "            for page in range(2, max_page+1):\n",
    "                newURL = self.URL.replace(temp, temp + f\"/page/{page}\")\n",
    "                r = self.driver.get(newURL)\n",
    "                time.sleep(rd.uniform(1,self.max_timer))\n",
    "                self.soup_result_page = BeautifulSoup(r.content, \"html5lib\")\n",
    "                self.scrape_result_page()\n",
    "                pbar.update(1)\n",
    "\n",
    "        pbar.close()\n",
    "        # Save data\n",
    "        if os.path.dirname(save_path):\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        with open(f'{save_path}.json', 'w') as f:\n",
    "            json.dump(self.gathered_data, f, indent=4)\n",
    "\n",
    "        if saveas_csv:\n",
    "            df = pd.DataFrame.from_dict(self.gathered_data, orient='index')\n",
    "            unpacked_df = df.pop(\"Release date\")\n",
    "            unpacked_columns = [i for i in df.columns.values]\n",
    "            for collumn in unpacked_columns:\n",
    "                temp = pd.json_normalize(df[collumn])\n",
    "                temp.columns = [f\"{collumn} - {subcol}\" for subcol in temp.columns]\n",
    "                temp.index = df.index\n",
    "                unpacked_df = pd.concat([unpacked_df, temp], axis=1)\n",
    "            unpacked_df.to_csv(f'{save_path}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1875a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = scraper(manufacturers=[\"Sony\"], max_timer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f09b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc41ab617da4bd5b2e447e0e4536bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scraping pages:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fa9fbce8224ab0909be93af9d4edf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scraping phones:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.phonearena.com/phones/manufacturers/sony/page/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3be02523e544de99ea71a071b3eebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scraping phones:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.start(save_path=\"EXAMPLE/Sony\", saveas_csv=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
